{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from utils_pos import get_word_tag, preprocess  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.1,0.3,0.2]\n",
    "b = [0.9,0.7,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.40794561, -1.56064775, -2.30258509])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(lambda x: math.log(x),a))) + np.array(list(map(lambda x: math.log(x),b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09568004859442561"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(2,51e-08) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the training corpus\n",
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    training_corpus = f.readlines()\n",
    "\n",
    "# load in the test corpus\n",
    "with open(\"WSJ_24.pos\", 'r') as f:\n",
    "    testing_corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size : 23777\n"
     ]
    }
   ],
   "source": [
    "## Create Vocab\n",
    "words = [line.split(\"\\t\")[0] for line in training_corpus]\n",
    "words_freq = Counter(words)\n",
    "vocab_list = [k for k, v in words_freq.items() if (v > 1 and k != '\\n')]\n",
    "## add unknown words in vocab\n",
    "unk_words_list = [\"--unk_digit--\",\"--unk_punct--\", \"--unk_upper--\",\"--unk_noun--\",\"--unk_verb--\",\"--unk_adj--\",\"--unk_adv--\",\"--unk--\",\"--n--\",\"\"]\n",
    "vocab_list = vocab_list + unk_words_list\n",
    "vocab_list.sort()\n",
    "vocab = {k:i for i,k in enumerate(sorted(vocab_list))}\n",
    "print(f\"Vocab Size : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unk(word):\n",
    "    punct = set(string.punctuation)\n",
    "    # Suffixes\n",
    "    noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "    verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "    adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "    adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    elif any(char in punct for char in word):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "    \n",
    "    return \"--unk--\"\n",
    "\n",
    "\n",
    "def get_word_tag(line, vocab):\n",
    "\n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocab:\n",
    "            word = assign_unk(word)\n",
    "        \n",
    "    return word,tag\n",
    "\n",
    "\n",
    "## Process train and test data\n",
    "train = [get_word_tag(line, vocab) for line in training_corpus]\n",
    "test = [get_word_tag(line, vocab) for line in testing_corpus]\n",
    "_, prep = preprocess(vocab, \"test.words\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(training_corpus, vocab):\n",
    "    ## Transition, Emission, tags count\n",
    "    transition_counts = defaultdict(int)\n",
    "    emission_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    prev_tag = \"--s--\"\n",
    "    for word, tag in train:\n",
    "        transition_counts[(prev_tag, tag)] += 1\n",
    "        emission_counts[(tag, word)] +=1\n",
    "        tag_counts[tag] +=1\n",
    "        prev_tag = tag\n",
    "\n",
    "    return emission_counts, transition_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pos tags : 46\n"
     ]
    }
   ],
   "source": [
    "states = sorted(tag_counts.keys())\n",
    "print(f\"Number of pos tags : {len(states)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition examples: \n",
      "(('--s--', 'IN'), 5050)\n",
      "(('IN', 'DT'), 32364)\n",
      "(('DT', 'NNP'), 9044)\n",
      "\n",
      "emission examples: \n",
      "(('DT', 'any'), 721)\n",
      "(('NN', 'decrease'), 7)\n",
      "(('NN', 'insider-trading'), 5)\n",
      "\n",
      "ambiguous word example: \n",
      "('RB', 'back') 304\n",
      "('VB', 'back') 20\n",
      "('RP', 'back') 84\n",
      "('JJ', 'back') 25\n",
      "('NN', 'back') 29\n",
      "('VBP', 'back') 4\n"
     ]
    }
   ],
   "source": [
    "print(\"transition examples: \")\n",
    "for ex in list(transition_counts.items())[:3]:\n",
    "    print(ex)\n",
    "print()\n",
    "\n",
    "print(\"emission examples: \")\n",
    "for ex in list(emission_counts.items())[200:203]:\n",
    "    print (ex)\n",
    "print()\n",
    "\n",
    "print(\"ambiguous word example: \")\n",
    "for tup,cnt in emission_counts.items():\n",
    "    if tup[1] == 'back': print (tup, cnt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888563993099213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(prep, y):\n",
    "\n",
    "    correct_pred = 0\n",
    "\n",
    "    for word, y_tup in zip(prep, y):\n",
    "\n",
    "        y_tup_l = y_tup.split()\n",
    "        if len(y_tup_l) == 2:\n",
    "            true_label = y_tup_l[1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        final_counts = 0\n",
    "        final_tag = \"\"\n",
    "\n",
    "        if word in vocab:\n",
    "            for tag in states:\n",
    "                key = (tag,word)\n",
    "                if key in emission_counts:\n",
    "                    count = emission_counts[key]\n",
    "                    if count>final_counts:\n",
    "                        final_tag = tag\n",
    "                        final_counts = count\n",
    "\n",
    "        if final_tag == true_label:\n",
    "            correct_pred +=1\n",
    "\n",
    "    \n",
    "    return correct_pred/len(test)\n",
    "\n",
    "calculate_accuracy(prep, testing_corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "num_tags = len(states)\n",
    "num_words = len(vocab)\n",
    "\n",
    "trasmission_mat = np.zeros((num_tags,num_tags))\n",
    "emission_mat = np.zeros((num_tags, num_words))\n",
    "\n",
    "for (prevtag,tag),value in dict(transition_counts).items():\n",
    "    trasmission_mat[states.index(prevtag), states.index(tag)] = value\n",
    "\n",
    "total = trasmission_mat.sum(axis=1).reshape(-1,1) + (alpha * num_tags)\n",
    "trasmission_mat = trasmission_mat + alpha\n",
    "trasmission_mat = trasmission_mat/total\n",
    "\n",
    "for (tag,word), value in emission_counts.items():\n",
    "    emission_mat[states.index(tag), vocab[word]] = value\n",
    "\n",
    "total = emission_mat.sum(axis=1).reshape(-1,1) + (alpha * num_words)\n",
    "emission_mat = emission_mat + alpha\n",
    "emission_mat = emission_mat/total\n",
    "\n",
    "assert all(trasmission_mat.sum(axis=1)), \"Transmission mat is not correct !!\" \n",
    "assert all(emission_mat.sum(axis=1)), \"Emission mat is not correct !!\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step(mu_prev,emission_probs,transition_probs,observed_state):\n",
    "#     pre_max = mu_prev * transition_probs.T\n",
    "#     max_prev_states = np.argmax(pre_max, axis=1)\n",
    "#     max_vals = pre_max[np.arange(len(max_prev_states)), max_prev_states]\n",
    "#     mu_new = max_vals * emission_probs[:, observed_state]\n",
    "#     return mu_new, max_prev_states\n",
    "\n",
    "\n",
    "# def viterbi(emission_probs,transition_probs,start_probs,observed_states):\n",
    "#     # Runs the forward pass, storing the most likely previous state.\n",
    "#     mu = start_probs * emission_probs[:, observed_states[0]]\n",
    "#     all_prev_states = []\n",
    "#     for observed_state in observed_states[1:]:\n",
    "#         mu, prevs = step(mu, emission_probs, transition_probs, observed_state)\n",
    "#         all_prev_states.append(prevs)\n",
    "    \n",
    "#     # Traces backwards to get the maximum likelihood sequence.\n",
    "#     state = np.argmax(mu)\n",
    "#     sequence_prob = mu[state]\n",
    "#     state_sequence = [state]\n",
    "#     for prev_states in all_prev_states[::-1]:\n",
    "#         state = prev_states[state]\n",
    "#         state_sequence.append(state)\n",
    "    \n",
    "#     return state_sequence[::-1], sequence_prob\n",
    "\n",
    "\n",
    "# s_idx = states.index(\"--s--\")\n",
    "# best_probs = np.zeros((num_tags, len(prep)))\n",
    "# best_paths = np.zeros((num_tags, len(prep)), dtype=int)\n",
    "# start_probs = trasmission_mat[s_idx,:]\n",
    "\n",
    "# ## test\n",
    "# observed_states = [vocab[w] for w in ['Loss', 'tracks','upward']]\n",
    "# max_seq, seq_prob = viterbi(emission_mat, trasmission_mat, start_probs, observed_states)\n",
    "# print([states[seq] for seq in max_seq])\n",
    "\n",
    "# observed_states = [vocab[w] for w in prep]\n",
    "# max_seq, seq_prob = viterbi(emission_mat, trasmission_mat, start_probs, observed_states)\n",
    "# pred = [states[seq] for seq in max_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
    "    num_tags = len(tag_counts)\n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
    "    s_idx = states.index(\"--s--\")\n",
    "    for i in range(num_tags): \n",
    "        if A[s_idx,i] == 0: \n",
    "            best_probs[i,0] = float('-inf')\n",
    "        else:\n",
    "            best_probs[i,0] = math.log(A[s_idx,i]) + math.log(B[i,vocab[corpus[0]]] )            \n",
    "    return best_probs, best_paths\n",
    "\n",
    "\n",
    "def viterbi_forward(A, B, test_corpus, best_probs, best_paths, vocab):\n",
    "   \n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for i in range(1, len(test_corpus)): \n",
    "        if i % 5000 == 0:\n",
    "            print(\"Words processed: {:>8}\".format(i))\n",
    "            \n",
    "        for j in range(num_tags): # complete this line\n",
    "            best_prob_i =  float(\"-inf\")\n",
    "            best_path_i = None\n",
    "            for k in range(num_tags): # complete this line\n",
    "                prob = best_probs[k,i-1]+ math.log(A[k,j]) +math.log(B[j,vocab[test_corpus[i]]])\n",
    "                if prob > best_prob_i: # complete this line\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "\n",
    "            best_probs[j,i] = best_prob_i\n",
    "            best_paths[j,i] = best_path_i\n",
    "\n",
    "    return best_probs, best_paths\n",
    "\n",
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "  \n",
    "    m = best_paths.shape[1] \n",
    "    z = [None] * m\n",
    "    num_tags = best_probs.shape[0]\n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    pred = [None] * m\n",
    "    \n",
    "    for k in range(num_tags): \n",
    "        if best_probs[k,-1]>best_prob_for_last_word: \n",
    "            best_prob_for_last_word = best_probs[k,-1]\n",
    "            z[m - 1]=k\n",
    "    pred[m - 1] = states[k]\n",
    "    \n",
    "    for i in range(len(corpus)-1, -1, -1):\n",
    "        pos_tag_for_word_i = best_paths[np.argmax(best_probs[:,i]),i]\n",
    "        z[i - 1] = best_paths[pos_tag_for_word_i,i]\n",
    "        pred[i - 1] = states[pos_tag_for_word_i]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words processed:     5000\n",
      "Words processed:    10000\n",
      "Words processed:    15000\n",
      "Words processed:    20000\n",
      "Words processed:    25000\n",
      "Words processed:    30000\n"
     ]
    }
   ],
   "source": [
    "best_probs, best_paths = initialize(states, tag_counts, trasmission_mat, emission_mat, prep, vocab)\n",
    "best_probs, best_paths = viterbi_forward(trasmission_mat, emission_mat, prep, best_probs, best_paths, vocab)\n",
    "pred = viterbi_backward(best_probs, best_paths, prep, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, y):\n",
    "    '''\n",
    "    Input: \n",
    "        pred: a list of the predicted parts-of-speech \n",
    "        y: a list of lines where each word is separated by a '\\t' (i.e. word \\t tag)\n",
    "    Output: \n",
    "        \n",
    "    '''\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for prediction, y in zip(pred, y):\n",
    "        word_tag_tuple = y.split()\n",
    "        \n",
    "        if len(word_tag_tuple)!=2: # complete this line\n",
    "            continue \n",
    "        word, tag = word_tag_tuple\n",
    "        if prediction == tag: # complete this line\n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    return (num_correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Viterbi algorithm is 0.9528\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the Viterbi algorithm is {compute_accuracy(pred, testing_corpus):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
