{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this notebook, we will explore two method\n",
    "    1. using dense one hot\n",
    "    2. using feature generation\n",
    "    3. Naive bayes\n",
    "    \n",
    "Preprocessing is not covered in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am happy because I am learning NLP',\n",
       " 'I am happy not sad',\n",
       " 'I am sad I am not learning NLP',\n",
       " 'I am sad not happy']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positive_tweets = [\n",
    "    'I am happy because I am learning NLP',\n",
    "    'I am happy not sad'\n",
    "]\n",
    "\n",
    "all_negative_tweets = [\n",
    "    'I am sad I am not learning NLP',\n",
    "    'I am sad not happy'\n",
    "]\n",
    "\n",
    "tweets = all_positive_tweets + all_negative_tweets\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method -1 : Dense One Hot Representation\n",
    "\n",
    "    - create feature matrix\n",
    "    - cons : not scalable, create problem when vocab size will increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'am', 'happy', 'because', 'I', 'am', 'learning', 'NLP'],\n",
       " ['I', 'am', 'happy', 'not', 'sad'],\n",
       " ['I', 'am', 'sad', 'I', 'am', 'not', 'learning', 'NLP'],\n",
       " ['I', 'am', 'sad', 'not', 'happy']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "tweets_tokenized = [tokenizer.tokenize(sent) for sent in tweets]\n",
    "tweets_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'NLP', 'not', 'because', 'happy', 'sad', 'learning']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(list(itertools.chain.from_iterable(tweets_tokenized))))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word =  dict(enumerate(vocab))\n",
    "word2idx =  {w:i for i,w in idx2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mat = np.zeros(shape = (len(tweets),len(idx2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,tweet_list in enumerate(tweets_tokenized):\n",
    "    for w in tweet_list:\n",
    "        feature_mat[i,word2idx[w]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>NLP</th>\n",
       "      <th>not</th>\n",
       "      <th>because</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I am happy because I am learning NLP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am happy not sad</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am sad I am not learning NLP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am sad not happy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        I   am  NLP  not  because  happy  sad  \\\n",
       "I am happy because I am learning NLP  1.0  1.0  1.0  0.0      1.0    1.0  0.0   \n",
       "I am happy not sad                    1.0  1.0  0.0  1.0      0.0    1.0  1.0   \n",
       "I am sad I am not learning NLP        1.0  1.0  1.0  1.0      0.0    0.0  1.0   \n",
       "I am sad not happy                    1.0  1.0  0.0  1.0      0.0    1.0  1.0   \n",
       "\n",
       "                                      learning  \n",
       "I am happy because I am learning NLP       1.0  \n",
       "I am happy not sad                         0.0  \n",
       "I am sad I am not learning NLP             1.0  \n",
       "I am sad not happy                         0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_mat, columns=word2idx, index=tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method -2 : Feature Generation\n",
    "\n",
    "    - here i am not doing any preprocessing.\n",
    "    - generate fetaures [bias, freq_of_word_in_positive_tweets, freq_of_word_in_positive_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************  Positve Tweets  ********************\n",
      "tokens :  [['I', 'am', 'happy', 'because', 'I', 'am', 'learning', 'NLP'], ['I', 'am', 'happy', 'not', 'sad']]\n",
      "words ['I', 'am', 'happy', 'because', 'I', 'am', 'learning', 'NLP', 'I', 'am', 'happy', 'not', 'sad']\n",
      "freq dict  dict_items([('I', 3), ('am', 3), ('happy', 2), ('because', 1), ('learning', 1), ('NLP', 1), ('not', 1), ('sad', 1)])\n",
      "\n",
      "\n",
      "\n",
      "********************  Negative Tweets  ********************\n",
      "tokens :  [['I', 'am', 'sad', 'I', 'am', 'not', 'learning', 'NLP'], ['I', 'am', 'sad', 'not', 'happy']]\n",
      "words ['I', 'am', 'happy', 'because', 'I', 'am', 'learning', 'NLP', 'I', 'am', 'happy', 'not', 'sad']\n",
      "freq dict  dict_items([('I', 3), ('am', 3), ('sad', 2), ('not', 2), ('learning', 1), ('NLP', 1), ('happy', 1)])\n",
      "\n",
      "\n",
      "********************  Vocab  ********************\n",
      "Complete Vocab : ['I', 'am', 'NLP', 'not', 'because', 'happy', 'sad', 'learning']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "print (\"*\"*20 + \"  Positve Tweets  \" + \"*\"*20)\n",
    "pos_tweets = [tokenizer.tokenize(sent) for sent in all_positive_tweets]\n",
    "print(\"tokens : \",pos_tweets)\n",
    "\n",
    "pos_words = list(itertools.chain.from_iterable(pos_tweets))\n",
    "print(\"words\",pos_words)\n",
    "\n",
    "pos_freq_dict = nltk.FreqDist(pos_words)\n",
    "print(\"freq dict \", pos_freq_dict.items())\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print (\"*\"*20 + \"  Negative Tweets  \" + \"*\"*20)\n",
    "neg_tweets = [tokenizer.tokenize(sent) for sent in all_negative_tweets]\n",
    "print(\"tokens : \",neg_tweets)\n",
    "\n",
    "neg_words = list(itertools.chain.from_iterable(neg_tweets))\n",
    "print(\"words\",pos_words)\n",
    "\n",
    "neg_freq_dict = nltk.FreqDist(neg_words)\n",
    "print(\"freq dict \", neg_freq_dict.items())\n",
    "\n",
    "print (\"\\n\\n\" + \"*\"*20 + \"  Vocab  \" + \"*\"*20)\n",
    "print(\"Complete Vocab :\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mat = np.zeros(shape = (len(tweets), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(tweets_tokenized):\n",
    "    feature_mat[i,0] = 1\n",
    "    pos_freq = 0\n",
    "    neg_freq = 0\n",
    "    for w in set(t):\n",
    "        pos_freq += pos_freq_dict[w]\n",
    "        neg_freq += neg_freq_dict[w]\n",
    "    feature_mat[i,1] = pos_freq\n",
    "    feature_mat[i,2] = neg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos dict  dict_items([('I', 3), ('am', 3), ('happy', 2), ('because', 1), ('learning', 1), ('NLP', 1), ('not', 1), ('sad', 1)])\n",
      "Neg dict  dict_items([('I', 3), ('am', 3), ('sad', 2), ('not', 2), ('learning', 1), ('NLP', 1), ('happy', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos dict \",pos_freq_dict.items())\n",
    "print(\"Neg dict \",neg_freq_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>pos_freq</th>\n",
       "      <th>neg_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I am happy because I am learning NLP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am happy not sad</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am sad I am not learning NLP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am sad not happy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bias  pos_freq  neg_freq\n",
       "I am happy because I am learning NLP   1.0      11.0       9.0\n",
       "I am happy not sad                     1.0      10.0      11.0\n",
       "I am sad I am not learning NLP         1.0      10.0      12.0\n",
       "I am sad not happy                     1.0      10.0      11.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_mat, index=tweets, columns=['bias','pos_freq','neg_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply logistic regression on above feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mehtod -3 : Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using pos_freq_dict and neg_freq_dict create dataframe\n",
    "df = pd.DataFrame(columns=['pos','neg'], index= vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pos_freq_dict.items():\n",
    "    df.loc[k,'pos'] = v\n",
    "    \n",
    "for k,v in neg_freq_dict.items():\n",
    "    df.loc[k,'neg'] = v\n",
    "    \n",
    "df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pos_freq = df.pos.sum()\n",
    "total_neg_freq = df.neg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_prob'] = df.pos/total_pos_freq\n",
    "df['neg_prob'] = df.neg/total_neg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos  neg  pos_prob  neg_prob\n",
       "I           3    3  0.230769  0.230769\n",
       "am          3    3  0.230769  0.230769\n",
       "NLP         1    1  0.076923  0.076923\n",
       "not         1    2  0.076923  0.153846\n",
       "because     1    0  0.076923  0.000000\n",
       "happy       2    1  0.153846  0.076923\n",
       "sad         1    2  0.076923  0.153846\n",
       "learning    1    1  0.076923  0.076923"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If you want to calculate the prob of tweet\n",
    "\n",
    "##### tweet = i am learning NLP => prob(i) * prob(am) * prob(learning) * prob(NLP)\n",
    "\n",
    "\n",
    "    Ratio(tweet) = P(pos) / P(neg)\n",
    "\n",
    "    if Ratio(tweet) >  1 then positive else negative sentiment\n",
    "    \n",
    "    \n",
    "    Problem : Some words have zero probability that will create the prob. Use laplacian smoothing to remove zero prob terms.\n",
    "    \n",
    "    p(w) = (p(w,class) + 1) / f(class) + N(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N_pos = > unique word in positive tweets\n",
    "# N_neg => unique words in negative tweets\n",
    "N_pos = len(pos_freq_dict)\n",
    "N_neg = len(neg_freq_dict)\n",
    "N_pos, N_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_prob_after_laplacian'] = (df.pos + 1)/(total_pos_freq+N_pos)\n",
    "df['neg_prob_after_laplacian'] = (df.neg + 1)/(total_neg_freq+N_neg)\n",
    "df['ratio(pos/neg)'] = df.pos_prob_after_laplacian / df.neg_prob_after_laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob_after_laplacian</th>\n",
       "      <th>neg_prob_after_laplacian</th>\n",
       "      <th>ratio(pos/neg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos  neg  pos_prob  neg_prob  pos_prob_after_laplacian  \\\n",
       "I           3    3  0.230769  0.230769                  0.190476   \n",
       "am          3    3  0.230769  0.230769                  0.190476   \n",
       "NLP         1    1  0.076923  0.076923                  0.095238   \n",
       "not         1    2  0.076923  0.153846                  0.095238   \n",
       "because     1    0  0.076923  0.000000                  0.095238   \n",
       "happy       2    1  0.153846  0.076923                  0.142857   \n",
       "sad         1    2  0.076923  0.153846                  0.095238   \n",
       "learning    1    1  0.076923  0.076923                  0.095238   \n",
       "\n",
       "          neg_prob_after_laplacian  ratio(pos/neg)  \n",
       "I                             0.20        0.952381  \n",
       "am                            0.20        0.952381  \n",
       "NLP                           0.10        0.952381  \n",
       "not                           0.15        0.634921  \n",
       "because                       0.05        1.904762  \n",
       "happy                         0.10        1.428571  \n",
       "sad                           0.15        0.634921  \n",
       "learning                      0.10        0.952381  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob_after_laplacian</th>\n",
       "      <th>neg_prob_after_laplacian</th>\n",
       "      <th>ratio(pos/neg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos  neg  pos_prob  neg_prob  pos_prob_after_laplacian  \\\n",
       "not         1    2  0.076923  0.153846                  0.095238   \n",
       "sad         1    2  0.076923  0.153846                  0.095238   \n",
       "I           3    3  0.230769  0.230769                  0.190476   \n",
       "am          3    3  0.230769  0.230769                  0.190476   \n",
       "NLP         1    1  0.076923  0.076923                  0.095238   \n",
       "learning    1    1  0.076923  0.076923                  0.095238   \n",
       "happy       2    1  0.153846  0.076923                  0.142857   \n",
       "because     1    0  0.076923  0.000000                  0.095238   \n",
       "\n",
       "          neg_prob_after_laplacian  ratio(pos/neg)  \n",
       "not                           0.15        0.634921  \n",
       "sad                           0.15        0.634921  \n",
       "I                             0.20        0.952381  \n",
       "am                            0.20        0.952381  \n",
       "NLP                           0.10        0.952381  \n",
       "learning                      0.10        0.952381  \n",
       "happy                         0.10        1.428571  \n",
       "because                       0.05        1.904762  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('ratio(pos/neg)')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As you can see from above table \n",
    "     \n",
    "     - positive words => hsappy because\n",
    "     - negative words => not sad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not        -0.454255\n",
       "sad        -0.454255\n",
       "I          -0.048790\n",
       "am         -0.048790\n",
       "NLP        -0.048790\n",
       "learning   -0.048790\n",
       "happy       0.356675\n",
       "because     0.644357\n",
       "Name: ratio(pos/neg), dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(df['ratio(pos/neg)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the scale used to  calculate the sentiment\n",
    "\n",
    "        p(w/pos)/p(w/neg) ==>  negative - neutral - positive\n",
    "                                 0          1      infinity\n",
    "                             \n",
    "                             \n",
    "                             \n",
    "        log(p(w/pos)/p(w/neg)) ==>    negative       - neutral       - positive\n",
    "                                      -infinity         0              infinity\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
